{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ResNet Recognition Model\n",
    "\n",
    "by FlÃ¡via Carvalhido"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train\n",
    "- input (2): path to the image folder, path to the csv with image paths and classes\n",
    "- output (1): trained model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.optim import lr_scheduler\n",
    "import torch.backends.cudnn as cudnn\n",
    "import numpy as np\n",
    "import torchvision\n",
    "from torchvision import datasets, models, transforms\n",
    "import os\n",
    "import copy\n",
    "import pandas as pd \n",
    "import shutil\n",
    "\n",
    "cudnn.benchmark = True"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Code adapted from PyTorch Tutorials : https://pytorch.org/tutorials/beginner/transfer_learning_tutorial.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ResNetTrain:\n",
    "    def __init__(self, img_folder_path=\"./train\", img_csv=\"./train.csv\"):\n",
    "        self.img_folder_path = img_folder_path\n",
    "        self.img_csv = img_csv\n",
    "\n",
    "        # Create directory with needed structure img_dir/class/img\n",
    "        os.mkdir('./temp_train')\n",
    "        df = pd.read_csv(self.img_csv)\n",
    "\n",
    "        self.class_names = df[df.columns[1]].unique()\n",
    "\n",
    "        for n in self.class_names:\n",
    "            os.mkdir('./temp_train/'+n)\n",
    "\n",
    "        for _, row in df.iterrows():\n",
    "            shutil.move(row[0], os.path.join('./temp_train/',row[1]))\n",
    "\n",
    "\n",
    "        # Preprocess images (same for test)\n",
    "        data_transforms = {\n",
    "            'train': transforms.Compose([\n",
    "                transforms.Resize(256),\n",
    "                transforms.CenterCrop(224),\n",
    "                transforms.ToTensor(),\n",
    "                transforms.Normalize([0.485, 0.456, 0.406], [\n",
    "                                     0.229, 0.224, 0.225])\n",
    "            ]),\n",
    "        }\n",
    "\n",
    "        image_datasets = {x: datasets.ImageFolder(os.path.join(self.img_folder_path, x),\n",
    "                                                data_transforms[x])\n",
    "                        for x in ['train']}\n",
    "        self.dataloaders = {x: torch.utils.data.DataLoader(image_datasets[x], batch_size=4,\n",
    "                                                    shuffle=True, num_workers=4)\n",
    "                    for x in ['train']}\n",
    "        self.dataset_sizes = {x: len(image_datasets[x]) for x in ['train']}\n",
    "        self.class_names = image_datasets['train'].classes #override\n",
    "\n",
    "        self.device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "\n",
    "    def train(self): \n",
    "\n",
    "        model_ft = models.resnet18(pretrained=True)\n",
    "        num_ftrs = model_ft.fc.in_features\n",
    "        # size of each output sample is set to the number of classes\n",
    "        model_ft.fc = nn.Linear(num_ftrs, len(self.class_names))\n",
    "\n",
    "        model_ft = model_ft.to(self.device)\n",
    "\n",
    "        criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "        # Observe that all parameters are being optimized\n",
    "        optimizer_ft = optim.SGD(model_ft.parameters(), lr=0.001, momentum=0.9)\n",
    "\n",
    "        # Decay LR by a factor of 0.1 every 7 epochs\n",
    "        exp_lr_scheduler = lr_scheduler.StepLR(optimizer_ft, step_size=7, gamma=0.1)\n",
    "\n",
    "        best_model_wts = copy.deepcopy(model_ft.state_dict())\n",
    "        best_acc = 0.0\n",
    "\n",
    "        for epoch in range(25):\n",
    "            print(f'Epoch {epoch}/{25 - 1}')\n",
    "            print('-' * 10)\n",
    "\n",
    "            # Each epoch has a training and validation phase\n",
    "            for phase in ['train', 'val']:\n",
    "                if phase == 'train':\n",
    "                    model_ft.train()  # Set model to training mode\n",
    "                else:\n",
    "                    model_ft.eval()   # Set model to evaluate mode\n",
    "\n",
    "                running_loss = 0.0\n",
    "                running_corrects = 0\n",
    "\n",
    "                # Iterate over data.\n",
    "                for inputs, labels in self.dataloaders[phase]:\n",
    "                    inputs = inputs.to(self.device)\n",
    "                    labels = labels.to(self.device)\n",
    "\n",
    "                    # zero the parameter gradients\n",
    "                    optimizer_ft.zero_grad()\n",
    "\n",
    "                    # forward\n",
    "                    # track history if only in train\n",
    "                    with torch.set_grad_enabled(phase == 'train'):\n",
    "                        outputs = model_ft(inputs)\n",
    "                        _, preds = torch.max(outputs, 1)\n",
    "                        loss = criterion(outputs, labels)\n",
    "\n",
    "                        # backward + optimize only if in training phase\n",
    "                        if phase == 'train':\n",
    "                            loss.backward()\n",
    "                            optimizer_ft.step()\n",
    "\n",
    "                    # statistics\n",
    "                    running_loss += loss.item() * inputs.size(0)\n",
    "                    running_corrects += torch.sum(preds == labels.data)\n",
    "                if phase == 'train':\n",
    "                    exp_lr_scheduler.step()\n",
    "\n",
    "                epoch_loss = running_loss / self.dataset_sizes[phase]\n",
    "                epoch_acc = running_corrects.double() / self.dataset_sizes[phase]\n",
    "\n",
    "                print(f'{phase} Loss: {epoch_loss:.4f} Acc: {epoch_acc:.4f}')\n",
    "\n",
    "                # deep copy the model\n",
    "                if phase == 'val' and epoch_acc > best_acc:\n",
    "                    best_acc = epoch_acc\n",
    "                    best_model_wts = copy.deepcopy(model_ft.state_dict())\n",
    "\n",
    "         \n",
    "\n",
    "        # load best model weights\n",
    "        model_ft.load_state_dict(best_model_wts)\n",
    "        return model_ft\n",
    "\n",
    "\n",
    "    def help(self):\n",
    "        print(\"Class ResNetTrain will train a ResNet recognition model with the provided arguments (in order): the training images folder path and the training images csv path. After initializing the class with the previously mentioned arguments, just call the method \\\"train\\\" and a trained ResNet model will be returned.\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test \n",
    "\n",
    "- input (3),  trained model, path to the image folder, path to the csv with image paths and [optional: classes]\n",
    "- output (2): 2D matrix of predictions (floats) for each image and class,  [optional, if ground truth is provided: accuracy]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.9"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "0cd1a84c6e748890eba993db88b6a1a54ba5ad1541d2f6351ed40b87eab1cc0f"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
